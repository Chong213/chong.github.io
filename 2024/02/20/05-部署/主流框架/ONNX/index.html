<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="x5-fullscreen" content="true">
<meta name="full-screen" content="yes">
<meta name="theme-color" content="#317EFB" />
<meta content="width=device-width, initial-scale=1.0, maximum-scale=5.0, user-scalable=0" name="viewport">
<meta name="description" content="ONNX https:&#x2F;&#x2F;cloud.tencent.com&#x2F;developer&#x2F;article&#x2F;2010635?areaSource&#x3D;102001.6&amp;traceId&#x3D;EbMpN_tKTIWhyhaA35fPg  1、简介ONNX 的本质只是一套开放的 ML 模型标准，模型文件存储的只是网络的拓扑结构和权重（其实每个深度学习框架最后保存的模型都是类似的），脱离开框架是没办法对模型直接进行">
<meta property="og:type" content="article">
<meta property="og:title">
<meta property="og:url" content="http://example.com/2024/02/20/05-%E9%83%A8%E7%BD%B2/%E4%B8%BB%E6%B5%81%E6%A1%86%E6%9E%B6/ONNX/index.html">
<meta property="og:site_name">
<meta property="og:description" content="ONNX https:&#x2F;&#x2F;cloud.tencent.com&#x2F;developer&#x2F;article&#x2F;2010635?areaSource&#x3D;102001.6&amp;traceId&#x3D;EbMpN_tKTIWhyhaA35fPg  1、简介ONNX 的本质只是一套开放的 ML 模型标准，模型文件存储的只是网络的拓扑结构和权重（其实每个深度学习框架最后保存的模型都是类似的），脱离开框架是没办法对模型直接进行">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/404.jpg">
<meta property="article:published_time" content="2024-02-20T08:24:02.683Z">
<meta property="article:modified_time" content="2023-09-27T02:58:26.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/404.jpg">




<!-- Favicon -->

    <link href='/img/favicon.svg?v=2.1.10' rel='icon' type='image/png' sizes='16x16' ></link>


    <link href='/img/favicon.svg?v=2.1.10' rel='icon' type='image/png' sizes='32x32' ></link>




<!-- Plugin -->




    
<link rel="stylesheet" href="/css/plugins/bootstrap.row.css">

    
<link rel="stylesheet" href="https://unpkg.com/@fancyapps/ui@4.0/dist/fancybox.css">

    
    




<!-- Icon -->

    
<link rel="stylesheet" href="/css/plugins/font-awesome.min.css">




<!-- Variable -->
<script>window.ASYNC_CONFIG = {"hostname":"example.com","author":null,"root":"/","typed_text":null,"theme_version":"2.1.10","theme":{"switch":true,"default":"style-light"},"favicon":{"logo":"/img/favicon.svg","icon16":"/img/favicon.svg","icon32":"/img/favicon.svg","appleTouchIcon":null,"webmanifest":null,"visibilitychange":false,"hidden":"/failure.ico","showText":"(/≧▽≦/)Hey! Good again!","hideText":"(●—●)Oh, crash!"},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}.","hits":"${hits} results found","hits_time":"${hits} results found in ${time} ms","author":"Post author: ","copyright_link":"Post link: ","copyright_license_title":"Copyright Notice: ","copyright_license_content":"All articles in this blog are licensed under undefined unless otherwise stated.","copy_success":"Copied","copy_failure":"Copy failed","open_read_mode":"Enter reading mode","exit_read_mode":"Exit reading mode","notice_outdate_message":"It has been undefined days since the last update, the content of the article may be outdated.","sticky":"TOP","just":"Just","min":"minutes ago","hour":"hours ago","day":"days ago","month":"months ago"},"swup":false,"plugin":{"flickr_justified_gallery":"https://unpkg.com/flickr-justified-gallery@latest/dist/fjGallery.min.js"},"icons":{"sun":"far fa-sun","moon":"far fa-moon","play":"fas fa-play","email":"far fa-envelope","next":"fas fa-arrow-right","calendar":"far fa-calendar-alt","clock":"far fa-clock","user":"far fa-user","back_top":"fas fa-arrow-up","close":"fas fa-times","search":"fas fa-search","reward":"fas fa-hand-holding-usd","user_tag":"fas fa-user-alt","toc_tag":"fas fa-th-list","read":"fas fa-book-reader","arrows":"fas fa-arrows-alt-h","double_arrows":"fas fa-angle-double-down","copy":"fas fa-copy"},"icontype":"font","highlight":{"plugin":"highlighjs","theme":true,"copy":true,"lang":true,"title":"default","height_limit":false},"toc":{"post_title":true},"live_time":{"start_time":"","prefix":"The blog has been lovely to run undefined day"}};</script>
<script id="async-page-config">window.PAGE_CONFIG = {"isPost":true,"isHome":false,"postUpdate":"2023-09-27 10:58:26"};</script>

<!-- Theme mode css -->
<link data-swup-theme rel="stylesheet" href="/css/index.css?v=2.1.10" id="trm-switch-style">
<script>
    let defaultMode = ASYNC_CONFIG.theme.default !=='auto' ?  ASYNC_CONFIG.theme.default : (window.matchMedia("(prefers-color-scheme: light)").matches ? 'style-light' : 'style-dark')
    let catchMode = localStorage.getItem('theme-mode') || defaultMode;
    let type = catchMode === 'style-dark' ? 'add' : 'remove';
    document.documentElement.classList[type]('dark')
</script>

<!-- CDN -->


    
    



<!-- Site Analytics -->
 
<meta name="generator" content="Hexo 7.1.1"></head>

<body>

  <!-- app wrapper -->
  <div class="trm-app-frame">

    <!-- page preloader -->
    <div class="trm-preloader">
    <div class="trm-holder">
        <div class="preloader">
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
            <div></div>
        </div>
    </div>
</div>
    <!-- page preloader end -->

    <!-- change mode preloader -->
    <div class="trm-mode-swich-animation-frame">
    <div class="trm-mode-swich-animation">
        <i class="i-sun"><i class="iconfont far fa-sun"></i></i>
        <div class="trm-horizon"></div>
        <i class="i-moon"><i class="iconfont far fa-moon"></i></i>
    </div>
</div>
    <!-- change mode preloader end -->

      <!-- scroll container -->
      <div id="trm-dynamic-content" class="trm-swup-animation">
        <div id="trm-scroll-container" class="trm-scroll-container" style="opacity: 0">
            <!-- top bar -->
            <header class="trm-top-bar">
	<div class="container">
		<div class="trm-left-side">
			<!-- logo -->
<a href="/" class="trm-logo-frame trm-anima-link">
    
        <img alt="logo" src="/img/favicon.svg">
    
    
        <div class="trm-logo-text">
            Cao<span>Chong</span>
        </div>
    
</a>
<!-- logo end -->
		</div>
		<div class="trm-right-side">
			<!-- menu -->
<div class="trm-menu">
    <nav>
        <ul>
            
            <li class="menu-item-has-children ">
                <a  href="/" target="">
                    Home
                </a>
                
            </li>
            
            <li class="menu-item-has-children ">
                <a  href="/archives/" target="">
                    Archives
                </a>
                
            </li>
            
        </ul>
    </nav>
</div>
<!-- menu end -->
			
    <!-- mode switcher place -->
    <div class="trm-mode-switcher-place">
        <div class="trm-mode-switcher">
            <i class="iconfont far fa-sun"></i>
            <input class="tgl tgl-light" id="trm-swich" type="checkbox">
            <label class="trm-swich" for="trm-swich"></label>
            <i class="iconfont far fa-moon"></i>
        </div>
    </div>
    <!-- mode switcher place end -->

			
		</div>
		<div class="trm-menu-btn">
			<span></span>
		</div>
	</div>
</header>
            <!-- top bar end -->

            <!-- body -->
            
<div class="trm-content-start">
    <!-- banner -->
    <div class="trm-banner">
    
    <!-- banner cover -->
    <img style="object-position:top;object-fit:cover;" alt="banner" class="trm-banner-cover" src="/img/banner.png">
    <!-- banner cover end -->
    

    <!-- banner content -->
    <div class="trm-banner-content trm-overlay">
        <div class="container">
            <div class="row">
                
                <div class="col-lg-4"></div>
                
                <div class="col-lg-8">

                    <!-- banner title -->
                    <div class="trm-banner-text ">
                        <div class="trm-label trm-mb-20">
                            NEWS LETTER
                        </div>
                        <h1 class="trm-mb-30 trm-hsmb-font">
                            
                        </h1>

                        
                            <ul class="trm-breadcrumbs trm-label">
                                <li>
                                    <a href="/" class="trm-anima-link">Home</a>
                                </li>
                                <li>
                                    <span>
                                        2024
                                    </span>
                                </li>
                            </ul>
                        
                    </div>
                    <!-- banner title end -->

                    <!-- scroll hint -->
                    <span id="scroll-triger" class="trm-scroll-hint-frame">
                        <div class="trm-scroll-hint"></div>
                        <span class="trm-label">Scroll down</span>
                    </span>
                    <!-- scroll hint end -->

                </div>
            </div>
        </div>
    </div>
    <!-- banner content end -->
</div>
    <!-- banner end -->
    <div class="container">
        <div class="row">
            
                <div class="trm-page-sidebar col-lg-4 hidden-sm">
                    <!-- main card -->
                    <div class="trm-main-card-frame trm-sidebar">
    <div class="trm-main-card"> 
        <!-- card header -->
<div class="trm-mc-header">
    <div class="trm-avatar-frame trm-mb-20">
        <img alt="Avatar" class="trm-avatar" src="/img/avatar.jpg">
    </div>
    <h5 class="trm-name trm-mb-15">
        星唯向导
    </h5>
    
</div>
<!-- card header end -->
        <!-- sidebar social -->

<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<div class="trm-social">
    
        <a href="https://github.com/chong-zzxy" title="Github" rel="nofollow" target="_blank">
            <i class="iconfont fab fa-github"></i>
        </a>
    
        <a href="https://gitee.com" title="gitee" rel="nofollow" target="_blank">
            <i class="iconfont iconfont cg-gitee"></i>
        </a>
    
        <a href="https://space.bilibili.com/271039719" title="BiliBili" rel="nofollow" target="_blank">
            <i class="iconfont iconfont icon-bilibili"></i>
        </a>
    
</div>

<!-- sidebar social end -->
        <!-- info -->
<div class="trm-divider trm-mb-40 trm-mt-40"></div>
<ul class="trm-table trm-mb-20">
    
        <li>
            <div class="trm-label">
                name:
            </div>
            <div class="trm-label trm-label-light">
                Caochong
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                from:
            </div>
            <div class="trm-label trm-label-light">
                China
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                born:
            </div>
            <div class="trm-label trm-label-light">
                1999.01.10
            </div>
        </li>
    
        <li>
            <div class="trm-label">
                love:
            </div>
            <div class="trm-label trm-label-light">
                AI | life | 粘粘
            </div>
        </li>
    
</ul>
<!-- info end -->

        
    </div>
</div>
                    <!-- main card end -->
                </div>
            
            <div class="trm-page-content col-lg-8">
                <div id="trm-content" class="trm-content">
                    <div class="trm-post-info row hidden-sm">
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-calendar-alt trm-icon"></i><br>
            02/20
        </div>
    </div>
    <div class="col-sm-4">
        <div class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-clock trm-icon"></i><br>
            16:24
        </div>
    </div>
    <div class="col-sm-4">
        <div id="post-author" class="trm-card trm-label trm-label-light text-center">
            <i class="iconfont far fa-user trm-icon"></i><br>
            
        </div>
    </div>
</div>
<div class="trm-card ">
    <article id="article-container" class="trm-publication">
    <h1 id="ONNX"><a href="#ONNX" class="headerlink" title="ONNX"></a>ONNX</h1><blockquote>
<p><a target="_blank" rel="noopener" href="https://cloud.tencent.com/developer/article/2010635?areaSource=102001.6&traceId=EbMpN_tKTIWhyhaA35fPg">https://cloud.tencent.com/developer/article/2010635?areaSource=102001.6&amp;traceId=EbMpN_tKTIWhyhaA35fPg</a></p>
</blockquote>
<h2 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h2><p>ONNX 的本质只是一套开放的 <code>ML</code> 模型标准，模型文件存储的只是网络的拓扑结构和权重（其实每个深度学习框架最后保存的模型都是类似的），脱离开框架是没办法对模型直接进行 <code>inference</code>的。</p>
<h2 id="2、存储格式"><a href="#2、存储格式" class="headerlink" title="2、存储格式"></a>2、存储格式</h2><p>ONNX 在底层是用 Protobuf 定义的。Protobuf，全称 Protocol Buffer，是 Google 提出的一套表示和序列化数据的机制。使用 Protobuf 时，用户需要先写一份数据定义文件，再根据这份定义文件把<a target="_blank" rel="noopener" href="https://cloud.tencent.com/product/cdcs?from_column=20065&from=20065">数据存储</a>进一份二进制文件。</p>
<p>可以说，<strong>数据定义文件就是数据类，二进制文件就是数据类的实例</strong>。</p>
<p><strong>一个不满足标准的 ONNX 模型可能无法被推理引擎正确识别</strong></p>
<h2 id="3、Python-API-使用"><a href="#3、Python-API-使用" class="headerlink" title="3、Python API 使用"></a>3、Python API 使用</h2><h3 id="3-1、加载模型"><a href="#3-1、加载模型" class="headerlink" title="3.1、加载模型"></a>3.1、加载模型</h3><ul>
<li>Loading an ONNX model<ul>
<li><pre><code class="Python">import onnx
# onnx_model is an in-mempry ModelProto
onnx_model = onnx.load(&#39;path/to/the/model.onnx&#39;)    # 加载 onnx 模型
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- Loading an ONNX Model with External Data</span><br><span class="line">  - 【默认加载模型方式】如果外部数据(`external data`)和模型文件在同一个目录下，仅使用 `onnx.load()` 即可加载模型，方法见上小节。</span><br><span class="line">  - 如果外部数据(`external data`)和模型文件不在同一个目录下，在使用 `onnx_load()` 函数后还需使用 `load_external_data_for_model()` 函数指定外部数据路径。</span><br><span class="line">  - ```Python</span><br><span class="line">    import onnxfrom onnx.external_data_helper</span><br><span class="line">    import load_external_data_for_model</span><br><span class="line">    </span><br><span class="line">    onnx_model = onnx.load(&#x27;path/to/the/model.onnx&#x27;, load_external_data=False)</span><br><span class="line">    load_external_data_for_model(onnx_model, &#x27;data/directory/path/&#x27;)</span><br><span class="line">    # Then the onnx_model has loaded the external data from the specific directory</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
</li>
<li>Converting an ONNX Model to External Data<ul>
<li><pre><code class="Python">from onnx.external_data_helper import convert_model_to_external_data
# onnx_model is an in-memory ModelProto
onnx_model = ...
convert_model_to_external_data(onnx_model, all_tensors_to_one_file=True, location=&#39;filename&#39;, size_threshold=1024, convert_attribute=False)
# Then the onnx_model has converted raw data as external data
# Must be followed by save
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 3.2、保存模型</span><br><span class="line"></span><br><span class="line">- Saving an ONNX Model</span><br><span class="line">  - ```Python</span><br><span class="line">    import onnx</span><br><span class="line">    </span><br><span class="line">    # onnx_model is an in-memory ModelProto</span><br><span class="line">    onnx_model = ...</span><br><span class="line">    </span><br><span class="line">    # Save the ONNX model</span><br><span class="line">    onnx.save(onnx_model, &#x27;path/to/the/model.onnx&#x27;)</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
</li>
<li>Converting and Saving an ONNX Model to External Data<ul>
<li><pre><code class="Python">import onnx
# onnx_model is an in-memory ModelProto
onnx_model = ...
onnx.save_model(onnx_model, &#39;path/to/save/the/model.onnx&#39;, save_as_external_data=True, all_tensors_to_one_file=True, location=&#39;filename&#39;, size_threshold=1024, convert_attribute=False)
# Then the onnx_model has converted raw data as external data and saved to specific di
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 3.3、Manipulating TensorProto and Numpy Array</span><br><span class="line"></span><br><span class="line">```Python</span><br><span class="line">import numpy</span><br><span class="line">import onnx</span><br><span class="line">from onnx import numpy_helper</span><br><span class="line"># Preprocessing: create a Numpy array</span><br><span class="line">numpy_array = numpy.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=float)</span><br><span class="line">print(&#x27;Original Numpy array:\n&#123;&#125;\n&#x27;.format(numpy_array))</span><br><span class="line"></span><br><span class="line"># Convert the Numpy array to a TensorProto</span><br><span class="line">tensor = numpy_helper.from_array(numpy_array)</span><br><span class="line">print(&#x27;TensorProto:\n&#123;&#125;&#x27;.format(tensor))</span><br><span class="line"></span><br><span class="line"># Convert the TensorProto to a Numpy array</span><br><span class="line">new_array = numpy_helper.to_array(tensor)</span><br><span class="line">print(&#x27;After round trip, Numpy array:\n&#123;&#125;\n&#x27;.format(new_array))</span><br><span class="line"></span><br><span class="line"># Save the TensorProto</span><br><span class="line">with open(&#x27;tensor.pb&#x27;, &#x27;wb&#x27;) as f:</span><br><span class="line">    f.write(tensor.SerializeToString())</span><br><span class="line">    </span><br><span class="line"># Load a TensorProto</span><br><span class="line">new_tensor = onnx.TensorProto()</span><br><span class="line">with open(&#x27;tensor.pb&#x27;, &#x27;rb&#x27;) as f:</span><br><span class="line">    new_tensor.ParseFromString(f.read())</span><br><span class="line">print(&#x27;After saving and loading, new TensorProto:\n&#123;&#125;&#x27;.format(new_tensor))</span><br></pre></td></tr></table></figure>
</code></pre>
</li>
</ul>
</li>
</ul>
<h3 id="3-4、创建ONNX模型"><a href="#3-4、创建ONNX模型" class="headerlink" title="3.4、创建ONNX模型"></a>3.4、创建ONNX模型</h3><p>可以通过 <code>helper</code> 模块提供的函数 <code>helper.make_graph</code> 完成创建 ONNX 格式的模型。</p>
<p>创建 <code>graph</code> 之前，需要先创建相应的 <code>NodeProto(node)</code>，参照文档设定节点的属性，指定该节点的输入与输出，如果该节点带有权重那还需要创建相应的<code>ValueInfoProto</code> 和 <code>TensorProto</code> 分别放入 <code>graph</code> 中的 <code>input</code> 和 <code>initializer</code> 中，以上步骤缺一不可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">from</span> onnx <span class="keyword">import</span> helper</span><br><span class="line"><span class="keyword">from</span> onnx <span class="keyword">import</span> AttributeProto, TensorProto, GraphProto</span><br><span class="line"></span><br><span class="line"><span class="comment"># The protobuf definition can be found here:</span></span><br><span class="line"><span class="comment"># https://github.com/onnx/onnx/blob/master/onnx/onnx.proto</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create one input (ValueInfoProto)</span></span><br><span class="line">X = helper.make_tensor_value_info(<span class="string">&#x27;X&#x27;</span>, TensorProto.FLOAT, [<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">pads = helper.make_tensor_value_info(<span class="string">&#x27;pads&#x27;</span>, TensorProto.FLOAT, [<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line">value = helper.make_tensor_value_info(<span class="string">&#x27;value&#x27;</span>, AttributeProto.FLOAT, [<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create one output (ValueInfoProto)</span></span><br><span class="line">Y = helper.make_tensor_value_info(<span class="string">&#x27;Y&#x27;</span>, TensorProto.FLOAT, [<span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a node (NodeProto) - This is based on Pad-11</span></span><br><span class="line">node_def = helper.make_node(</span><br><span class="line">    <span class="string">&#x27;Pad&#x27;</span>,                  <span class="comment"># name</span></span><br><span class="line">    [<span class="string">&#x27;X&#x27;</span>, <span class="string">&#x27;pads&#x27;</span>, <span class="string">&#x27;value&#x27;</span>], <span class="comment"># inputs</span></span><br><span class="line">    [<span class="string">&#x27;Y&#x27;</span>],                  <span class="comment"># outputs</span></span><br><span class="line">    mode=<span class="string">&#x27;constant&#x27;</span>,        <span class="comment"># attributes</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the graph (GraphProto)</span></span><br><span class="line">graph_def = helper.make_graph(</span><br><span class="line">    [node_def],        <span class="comment"># nodes</span></span><br><span class="line">    <span class="string">&#x27;test-model&#x27;</span>,      <span class="comment"># name</span></span><br><span class="line">    [X, pads, value],  <span class="comment"># inputs</span></span><br><span class="line">    [Y],               <span class="comment"># outputs</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the model (ModelProto)</span></span><br><span class="line">model_def = helper.make_model(graph_def, producer_name=<span class="string">&#x27;onnx-example&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The model is:\n&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(model_def))onnx.checker.check_model(model_def)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The model is checked!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-5、检查模型"><a href="#3-5、检查模型" class="headerlink" title="3.5、检查模型"></a>3.5、检查模型</h3><p>在完成 <code>ONNX</code> 模型加载或者创建后，有必要对模型进行检查，使用 <code>onnx.check.check_model()</code> 函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="comment"># Preprocessing: load the ONNX model</span></span><br><span class="line">model_path = <span class="string">&#x27;path/to/the/model.onnx&#x27;</span></span><br><span class="line">onnx_model = onnx.load(model_path)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;The model is:\n&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(onnx_model))</span><br><span class="line"><span class="comment"># Check the model</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    onnx.checker.check_model(onnx_model)</span><br><span class="line"><span class="keyword">except</span> onnx.checker.ValidationError <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;The model is invalid: %s&#x27;</span> % e)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;The model is valid!&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-6、实用功能函数"><a href="#3-6、实用功能函数" class="headerlink" title="3.6、实用功能函数"></a>3.6、实用功能函数</h3><p>函数 <code>extract_model()</code> 可以从 <code>ONNX</code> 模型中提取子模型，子模型由输入和输出张量的名称定义。这个功能方便我们 <code>debug</code> 原模型和转换后的 <code>ONNX</code> 模型输出结果是否一致(误差小于某个阈值)，不再需要我们手动去修改 <code>ONNX</code> 模型。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxinput_path = <span class="string">&#x27;path/to/the/original/model.onnx&#x27;</span></span><br><span class="line">output_path = <span class="string">&#x27;path/to/save/the/extracted/model.onnx&#x27;</span></span><br><span class="line"></span><br><span class="line">input_names = [<span class="string">&#x27;input_0&#x27;</span>, <span class="string">&#x27;input_1&#x27;</span>, <span class="string">&#x27;input_2&#x27;</span>]</span><br><span class="line">output_names = [<span class="string">&#x27;output_0&#x27;</span>, <span class="string">&#x27;output_1&#x27;</span>]</span><br><span class="line"></span><br><span class="line">onnx.utils.extract_model(input_path, output_path, input_names, output_names)</span><br></pre></td></tr></table></figure>

<h3 id="3-7、工具"><a href="#3-7、工具" class="headerlink" title="3.7、工具"></a>3.7、工具</h3><p>函数 <code>update_inputs_outputs_dims()</code> 可以将模型输入和输出的维度更新为参数中指定的值，可以使用 <code>dim_param</code> 提供静态和动态尺寸大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> onnxfrom onnx.tools <span class="keyword">import</span> update_model_dims</span><br><span class="line"></span><br><span class="line">model = onnx.load(<span class="string">&#x27;path/to/the/model.onnx&#x27;</span>)</span><br><span class="line"><span class="comment"># Here both &#x27;seq&#x27;, &#x27;batcXh&#x27; and -1 are dynamic using dim_param.</span></span><br><span class="line">variable_length_model = update_model_dims.update_inputs_outputs_dims(model, &#123;<span class="string">&#x27;input_name&#x27;</span>: [<span class="string">&#x27;seq&#x27;</span>, <span class="string">&#x27;batch&#x27;</span>, <span class="number">3</span>, -<span class="number">1</span>]&#125;, &#123;<span class="string">&#x27;output_name&#x27;</span>: [<span class="string">&#x27;seq&#x27;</span>, <span class="string">&#x27;batch&#x27;</span>, <span class="number">1</span>, -<span class="number">1</span>]&#125;)</span><br><span class="line"><span class="comment"># need to check model after the input/output sizes are updated</span></span><br><span class="line">onnx.checker.check_model(variable_length_model )</span><br></pre></td></tr></table></figure>

<h3 id="3-8、输出-ONNX-中间节点的值"><a href="#3-8、输出-ONNX-中间节点的值" class="headerlink" title="3.8、输出 ONNX 中间节点的值"></a>3.8、输出 ONNX 中间节点的值</h3><p>在使用 ONNX 模型时，最常见的一个需求是能够用推理引擎输出中间节点的值。这多见于深度学习框架模型和 ONNX 模型的精度对齐中，因为只要能够输出中间节点的值，就能定位到精度出现偏差的算子。我们来看看如何用子模型提取实现这一任务。</p>
<p>在刚刚的第一个子模型提取示例中，我们添加了一条原来模型中不存在的输出边。用同样的原理，我们可以在保持原有输入输出不变的同时，新增加一些输出，提取出一个能输出中间节点的”子模型“。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">onnx.utils.extract_model(<span class="string">&#x27;whole_model.onnx&#x27;</span>, <span class="string">&#x27;more_output_model.onnx&#x27;</span>, [<span class="string">&#x27;input.1&#x27;</span>], [<span class="string">&#x27;31&#x27;</span>, <span class="string">&#x27;23&#x27;</span>, <span class="string">&#x27;25&#x27;</span>, <span class="string">&#x27;27&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>在这个子模型中，我们在保持原有的输入 <code>input.1</code>，输出 <code>31</code> 的同时，把其他几个边加入了输出中。如下图所示：</p>
<p><img src="https://qgd5xm63s9.feishu.cn/space/api/box/stream/download/asynccode/?code=ZDJmMmRjYjFiNzZhMzA5NTM1MTYxZjcxM2MyZjU2N2NfWEdCNG5WcW5QNVE0VFZmdTZyc241a005dFlTZXFYMzJfVG9rZW46WDhzMmJkREx4bzFycnh4TTZiWGNnRXpYbmhiXzE2OTU3ODMzODQ6MTY5NTc4Njk4NF9WNA" alt="img" loading="lazy" onerror='this.onerror=null;this.src="/img/404.jpg"'></p>
<p>这样，用 ONNX Runtime 运行 <code>more_output_model.onnx</code> 这个模型时，我们就能得到更多的输出了。</p>
<p>为了方便调试，我们还可以把原模型拆分成多个互不相交的子模型。这样，在每次调试时，可以只对原模型的部分子模块调试。比如：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">onnx.<span class="property">utils</span>.<span class="title function_">extract_model</span>(<span class="string">&#x27;whole_model.onnx&#x27;</span>, <span class="string">&#x27;debug_model_1.onnx&#x27;</span>, [<span class="string">&#x27;input.1&#x27;</span>], [<span class="string">&#x27;23&#x27;</span>])</span><br><span class="line">onnx.<span class="property">utils</span>.<span class="title function_">extract_model</span>(<span class="string">&#x27;whole_model.onnx&#x27;</span>, <span class="string">&#x27;debug_model_2.onnx&#x27;</span>, [<span class="string">&#x27;23&#x27;</span>], [<span class="string">&#x27;25&#x27;</span>])</span><br><span class="line">onnx.<span class="property">utils</span>.<span class="title function_">extract_model</span>(<span class="string">&#x27;whole_model.onnx&#x27;</span>, <span class="string">&#x27;debug_model_3.onnx&#x27;</span>, [<span class="string">&#x27;23&#x27;</span>], [<span class="string">&#x27;27&#x27;</span>])</span><br><span class="line">onnx.<span class="property">utils</span>.<span class="title function_">extract_model</span>(<span class="string">&#x27;whole_model.onnx&#x27;</span>, <span class="string">&#x27;debug_model_4.onnx&#x27;</span>, [<span class="string">&#x27;25&#x27;</span>, <span class="string">&#x27;27&#x27;</span>], [<span class="string">&#x27;31&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>子模型提取固然是一个便利的 ONNX 调试工具。但是，在实际的情况中，我们一般是用 PyTorch 等框架导出 ONNX 模型。这里有两个问题：</p>
<p>1）一旦 PyTorch 模型改变，ONNX 模型的边序号也会改变。这样每次提取同样的子模块时都要重新去 ONNX 模型里查序号，如此繁琐的调试方法是不会在实践中采用的。</p>
<p>2）即使我们能保证 ONNX 的边序号不发生改变，我们也难以把 PyTorch 代码和 ONNX 节点对应起来——当模型结构变得十分复杂时，要识别 ONNX 中每个节点的含义是不可能的。</p>
<h2 id="4、总结"><a href="#4、总结" class="headerlink" title="4、总结"></a>4、总结</h2><ul>
<li>ONNX 使用 Protobuf 定义规范和序列化模型。</li>
<li>一个 ONNX 模型主要由 <code>ModelProto</code>,<code>GraphProto</code>,<code>NodeProto</code>,<code>ValueInfoProto</code> 这几个数据类的对象组成。</li>
<li>使用 <code>onnx.helper.make_xxx</code>，我们可以构造 ONNX 模型的数据对象。</li>
<li><code>onnx.save()</code> 可以保存模型，<code>onnx.load()</code> 可以读取模型，<code>onnx.checker.check_model()</code> 可以检查模型是否符合规范。</li>
<li><code>onnx.utils.extract_model()</code> 可以从原模型中取出部分节点，和新定义的输入、输出边构成一个新的子模型。</li>
<li>利用子模型提取功能，我们可以输出原 ONNX 模型的中间结果，实现对 ONNX 模型的调试。</li>
</ul>

</article>
    
    

</div>
<div class="trm-post-next-prev row">
    <div class="col-lg-12">
        <!-- title -->
        <h5 class="trm-title-with-divider">
            Other Articles
            <span data-number="02"></span>
        </h5>
    </div>
    
        <div class="col-lg-6">
    <div class="trm-blog-card trm-scroll-animation">
        <a href="/2024/02/20/05-%E9%83%A8%E7%BD%B2/%E4%B8%BB%E6%B5%81%E6%A1%86%E6%9E%B6/TensorRT/" class="trm-cover-frame trm-anima-link">
            
            
                <img alt="cover" class="no-fancybox" src="/img/block.jpg">
            
        </a>
        
        <div class="trm-card-descr">
            <div class="trm-label trm-category trm-mb-20">
                <a href=" #.">
                    Unclassified
                </a>
            </div>
            <h5>
                <a href="/2024/02/20/05-%E9%83%A8%E7%BD%B2/%E4%B8%BB%E6%B5%81%E6%A1%86%E6%9E%B6/TensorRT/" class="trm-anima-link">
                    
                </a>
            </h5>
            <div class="trm-divider trm-mb-20 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>24/02/20</li>
                <li>16:24</li>
                
                
            </ul>
        </div>
    </div>
</div>
    
    
        <div class="col-lg-6">
    <div class="trm-blog-card trm-scroll-animation">
        <a href="/2024/02/20/05-%E9%83%A8%E7%BD%B2/%E5%89%AA%E6%9E%9D%E9%87%8F%E5%8C%96%E8%92%B8%E9%A6%8F/" class="trm-cover-frame trm-anima-link">
            
            
                <img alt="cover" class="no-fancybox" src="/img/block.jpg">
            
        </a>
        
        <div class="trm-card-descr">
            <div class="trm-label trm-category trm-mb-20">
                <a href=" #.">
                    Unclassified
                </a>
            </div>
            <h5>
                <a href="/2024/02/20/05-%E9%83%A8%E7%BD%B2/%E5%89%AA%E6%9E%9D%E9%87%8F%E5%8C%96%E8%92%B8%E9%A6%8F/" class="trm-anima-link">
                    
                </a>
            </h5>
            <div class="trm-divider trm-mb-20 trm-mt-20"></div>
            <ul class="trm-card-data trm-label">
                <li>24/02/20</li>
                <li>16:24</li>
                
                
            </ul>
        </div>
    </div>
</div>
    
</div>

    



                    <div class="trm-divider footer-divider"></div>

                    <!-- footer -->
                    <footer class="trm-scroll-animation">

    

    
        <div class="trm-footer-item">
            <span>© 2020- 2024</span>
            <span class="footer-separator"data-separator=" · "></span>
            <span class="trm-accent-color">星唯向导</span>
        </div>
    


    <!--添加运行时间-->
    <span id="sitetime"></span>
    <script language=javascript>
	    function siteTime(){
		    window.setTimeout("siteTime()", 1000);
		    var seconds = 1000;
		    var minutes = seconds * 60;
		    var hours = minutes * 60;
		    var days = hours * 24;
		    var years = days * 365;
		    var today = new Date();
		    var todayYear = today.getFullYear();
		    var todayMonth = today.getMonth()+1;
		    var todayDate = today.getDate();
		    var todayHour = today.getHours();
		    var todayMinute = today.getMinutes();
		    var todaySecond = today.getSeconds();
		/* 
        Date.UTC() -- 返回date对象距世界标准时间(UTC)1970年1月1日午夜之间的毫秒数(时间戳)
        year - 作为date对象的年份，为4位年份值
        month - 0-11之间的整数，做为date对象的月份
        day - 1-31之间的整数，做为date对象的天数
        hours - 0(午夜24点)-23之间的整数，做为date对象的小时数
        minutes - 0-59之间的整数，做为date对象的分钟数
        seconds - 0-59之间的整数，做为date对象的秒数
        microseconds - 0-999之间的整数，做为date对象的毫秒数
        */
		    var t1 = Date.UTC(2023,05,25,18,12,20); //北京时间2018-2-13 00:00:00
		    var t2 = Date.UTC(todayYear,todayMonth,todayDate,todayHour,todayMinute,todaySecond);
		    var diff = t2-t1;
		    var diffYears = Math.floor(diff/years);
		    var diffDays = Math.floor((diff/days)-diffYears*365);
		    var diffHours = Math.floor((diff-(diffYears*365+diffDays)*days)/hours);
		    var diffMinutes = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours)/minutes);
		    var diffSeconds = Math.floor((diff-(diffYears*365+diffDays)*days-diffHours*hours-diffMinutes*minutes)/seconds);
		    document.getElementById("sitetime").innerHTML=" 已运行"+/*diffYears+" 年 "+*/diffDays+" 天 "+diffHours+" 小时 "+diffMinutes+" 分钟 "+diffSeconds+" 秒";
	    }
	    siteTime();
    </script>
    <!--// 添加运行时间-->

      

     

    
        <div class="trm-footer-item">
            在年轻的飞奔里，拥抱迎面而来的风~
        </div>
     
</footer>
                    <!-- footer end -->

                </div>
            </div>
        </div>
    </div>
</div>
            <!-- body end -->

            

    <div id="post-toc" class="trm-post-toc">
      <div class="trm-post-toc-header">
        Article table of contents
				<span id="post-toc-top">
					TOP
				</span>
      </div>
      <div class="trm-post-toc-content">
        <ol class="trm-toc"><li class="trm-toc-item trm-toc-level-1" title="ONNX"><a rel="nofollow" class="trm-toc-link" href="#ONNX"><span class="trm-toc-number">1.</span> <span class="trm-toc-text">ONNX</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-2" title="1、简介"><a rel="nofollow" class="trm-toc-link" href="#1、简介"><span class="trm-toc-number">1.1.</span> <span class="trm-toc-text">1、简介</span></a></li><li class="trm-toc-item trm-toc-level-2" title="2、存储格式"><a rel="nofollow" class="trm-toc-link" href="#2、存储格式"><span class="trm-toc-number">1.2.</span> <span class="trm-toc-text">2、存储格式</span></a></li><li class="trm-toc-item trm-toc-level-2" title="3、Python API 使用"><a rel="nofollow" class="trm-toc-link" href="#3、Python-API-使用"><span class="trm-toc-number">1.3.</span> <span class="trm-toc-text">3、Python API 使用</span></a><ol class="trm-toc-child"><li class="trm-toc-item trm-toc-level-3" title="3.1、加载模型"><a rel="nofollow" class="trm-toc-link" href="#3-1、加载模型"><span class="trm-toc-number">1.3.1.</span> <span class="trm-toc-text">3.1、加载模型</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.4、创建ONNX模型"><a rel="nofollow" class="trm-toc-link" href="#3-4、创建ONNX模型"><span class="trm-toc-number">1.3.2.</span> <span class="trm-toc-text">3.4、创建ONNX模型</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.5、检查模型"><a rel="nofollow" class="trm-toc-link" href="#3-5、检查模型"><span class="trm-toc-number">1.3.3.</span> <span class="trm-toc-text">3.5、检查模型</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.6、实用功能函数"><a rel="nofollow" class="trm-toc-link" href="#3-6、实用功能函数"><span class="trm-toc-number">1.3.4.</span> <span class="trm-toc-text">3.6、实用功能函数</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.7、工具"><a rel="nofollow" class="trm-toc-link" href="#3-7、工具"><span class="trm-toc-number">1.3.5.</span> <span class="trm-toc-text">3.7、工具</span></a></li><li class="trm-toc-item trm-toc-level-3" title="3.8、输出 ONNX 中间节点的值"><a rel="nofollow" class="trm-toc-link" href="#3-8、输出-ONNX-中间节点的值"><span class="trm-toc-number">1.3.6.</span> <span class="trm-toc-text">3.8、输出 ONNX 中间节点的值</span></a></li></ol></li><li class="trm-toc-item trm-toc-level-2" title="4、总结"><a rel="nofollow" class="trm-toc-link" href="#4、总结"><span class="trm-toc-number">1.4.</span> <span class="trm-toc-text">4、总结</span></a></li></ol></li></ol>
      </div>
    </div>

            
<div class="trm-fixed-container">
    
        <div class="trm-fixed-btn post-toc-btn" data-title="Open toc">
            <i class="iconfont fas fa-th-list"></i>
        </div>
    
    
        <div class="trm-fixed-btn" data-title="Read Mode" onclick="asyncFun.switchReadMode()">
            <i class="iconfont fas fa-book-reader"></i>
        </div>
    
    
    <div id="trm-back-top" class="trm-fixed-btn" data-title="Back To Top">
        <i class="iconfont fas fa-arrow-up"></i>
    </div>
</div>
        </div>
      </div>
      <!-- scroll container end -->
  </div>
  <!-- app wrapper end -->

  
  <!-- Plugin -->




    
    
<script src="https://unpkg.com/@fancyapps/ui@4.0/dist/fancybox.umd.js"></script>

    

    

    

    <!-- 数学公式 -->
    

    <!-- 评论插件 -->
    
        

        
    



<!-- CDN -->


    

    

    




    <!-- Service Worker -->
    
    <!-- baidu push -->
    


<script id="async-script" src="/js/main.js?v=2.1.10"></script>

</body>

</html>